{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecb5cc5d",
   "metadata": {},
   "source": [
    "## üì¶ Step 1: Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f2a340",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q youtube-transcript-api\n",
    "!pip install -q langchain\n",
    "!pip install -q langchain-openai\n",
    "!pip install -q langchain-huggingface\n",
    "!pip install -q langchain-community\n",
    "!pip install -q langchain-text-splitters\n",
    "!pip install -q langchain-chroma\n",
    "!pip install -q chromadb\n",
    "!pip install -q openai\n",
    "!pip install -q gradio\n",
    "!pip install -q huggingface_hub\n",
    "!pip install -q sentence-transformers\n",
    "!pip install -q torch\n",
    "print(\"‚úÖ All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2e71cc",
   "metadata": {},
   "source": [
    "## üîë Step 2: Choose AI Provider & Set API Keys\n",
    "\n",
    "### Option A: OpenAI (Paid - Best Quality)\n",
    "- **Cost:** ~$0.0004 per 1K tokens (~$0.02 per video)\n",
    "- **Models:** GPT-3.5-turbo, text-embedding-ada-002\n",
    "- **Get key:** https://platform.openai.com/api-keys\n",
    "\n",
    "### Option B: HuggingFace (FREE! üéâ)\n",
    "- **Cost:** Completely free!\n",
    "- **Models:** Mistral-7B-Instruct, all-MiniLM-L6-v2\n",
    "- **Get token:** https://huggingface.co/settings/tokens\n",
    "\n",
    "**Change `AI_PROVIDER` below to your choice:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0094ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# ========================================\n",
    "# CHOOSE YOUR AI PROVIDER HERE\n",
    "# ========================================\n",
    "AI_PROVIDER = \"HuggingFace\"  # Options: \"OpenAI\" or \"HuggingFace\"\n",
    "# ========================================\n",
    "\n",
    "print(f\"ü§ñ Selected AI Provider: {AI_PROVIDER}\\n\")\n",
    "\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    use_secrets = True\n",
    "except:\n",
    "    use_secrets = False\n",
    "\n",
    "if AI_PROVIDER == \"OpenAI\":\n",
    "    print(\"üìù OpenAI Setup\")\n",
    "    print(\"Get your API key from: https://platform.openai.com/api-keys\\n\")\n",
    "    \n",
    "    if use_secrets:\n",
    "        try:\n",
    "            OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
    "            print(\"‚úÖ OpenAI API key loaded from Colab Secrets\")\n",
    "        except:\n",
    "            OPENAI_API_KEY = input(\"Enter your OpenAI API key: \")\n",
    "            print(\"‚úÖ OpenAI API key entered\")\n",
    "    else:\n",
    "        OPENAI_API_KEY = input(\"Enter your OpenAI API key: \")\n",
    "        print(\"‚úÖ OpenAI API key entered\")\n",
    "    \n",
    "    os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "    \n",
    "elif AI_PROVIDER == \"HuggingFace\":\n",
    "    print(\"üìù HuggingFace Setup (FREE!)\")\n",
    "    print(\"Get your token from: https://huggingface.co/settings/tokens\\n\")\n",
    "    \n",
    "    if use_secrets:\n",
    "        try:\n",
    "            HF_TOKEN = userdata.get('HF_TOKEN')\n",
    "            print(\"‚úÖ HuggingFace token loaded from Colab Secrets\")\n",
    "        except:\n",
    "            HF_TOKEN = input(\"Enter your HuggingFace token: \")\n",
    "            print(\"‚úÖ HuggingFace token entered\")\n",
    "    else:\n",
    "        HF_TOKEN = input(\"Enter your HuggingFace token: \")\n",
    "        print(\"‚úÖ HuggingFace token entered\")\n",
    "    \n",
    "    os.environ['HUGGINGFACEHUB_API_TOKEN'] = HF_TOKEN\n",
    "\n",
    "print(f\"\\n‚úÖ {AI_PROVIDER} configured successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59136e25",
   "metadata": {},
   "source": [
    "## üìö Step 3: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53310c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from youtube_transcript_api._errors import TranscriptsDisabled, NoTranscriptFound\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain.chains.retrieval_qa.base import RetrievalQA\n",
    "import json\n",
    "\n",
    "# Import provider-specific libraries\n",
    "if AI_PROVIDER == \"OpenAI\":\n",
    "    from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "    print(\"‚úÖ OpenAI libraries imported\")\n",
    "elif AI_PROVIDER == \"HuggingFace\":\n",
    "    from langchain_huggingface import HuggingFaceEmbeddings, HuggingFaceEndpoint\n",
    "    from huggingface_hub import InferenceClient\n",
    "    print(\"‚úÖ HuggingFace libraries imported\")\n",
    "\n",
    "print(\"‚úÖ All libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6557cd3",
   "metadata": {},
   "source": [
    "## üé¨ Step 4: YouTube Transcript Fetcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef424269",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YouTubeTranscriptFetcher:\n",
    "    \"\"\"Fetches YouTube video transcripts\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_video_id(url: str) -> str:\n",
    "        \"\"\"Extract video ID from YouTube URL\"\"\"\n",
    "        if \"youtube.com\" in url or \"youtu.be\" in url:\n",
    "            if \"v=\" in url:\n",
    "                return url.split(\"v=\")[1].split(\"&\")[0]\n",
    "            elif \"youtu.be/\" in url:\n",
    "                return url.split(\"youtu.be/\")[1].split(\"?\")[0]\n",
    "        return url  # Already a video ID\n",
    "    \n",
    "    def fetch_transcript(self, video_id: str) -> dict:\n",
    "        \"\"\"Fetch transcript for a single video\"\"\"\n",
    "        video_id = self.extract_video_id(video_id)\n",
    "        \n",
    "        try:\n",
    "            # Get transcript\n",
    "            transcript_list = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "            \n",
    "            # Combine all text\n",
    "            full_text = \" \".join([entry['text'] for entry in transcript_list])\n",
    "            \n",
    "            return {\n",
    "                'video_id': video_id,\n",
    "                'transcript': full_text,\n",
    "                'segments': transcript_list,\n",
    "                'length': len(full_text)\n",
    "            }\n",
    "        except TranscriptsDisabled:\n",
    "            raise Exception(f\"‚ùå Transcripts are disabled for video: {video_id}\")\n",
    "        except NoTranscriptFound:\n",
    "            raise Exception(f\"‚ùå No transcript found for video: {video_id}\")\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"‚ùå Error: {str(e)}\")\n",
    "    \n",
    "    def fetch_multiple(self, video_ids: list) -> list:\n",
    "        \"\"\"Fetch transcripts for multiple videos\"\"\"\n",
    "        transcripts = []\n",
    "        print(f\"\\nüì• Fetching {len(video_ids)} video(s)...\\n\")\n",
    "        \n",
    "        for i, video_id in enumerate(video_ids, 1):\n",
    "            print(f\"[{i}/{len(video_ids)}] Processing: {video_id}\")\n",
    "            try:\n",
    "                transcript = self.fetch_transcript(video_id)\n",
    "                transcripts.append(transcript)\n",
    "                chars = transcript['length']\n",
    "                print(f\"  ‚úÖ Success! Got {chars:,} characters\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"  {str(e)}\\n\")\n",
    "        \n",
    "        return transcripts\n",
    "\n",
    "print(\"‚úÖ Transcript fetcher ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa2f96d",
   "metadata": {},
   "source": [
    "## üéØ Step 5: Add Your YouTube Videos\n",
    "\n",
    "Enter video IDs or full URLs (comma-separated)\n",
    "\n",
    "**Examples:**\n",
    "- `dQw4w9WgXcQ`\n",
    "- `https://www.youtube.com/watch?v=dQw4w9WgXcQ`\n",
    "- `jNQXAC9IVRw, 9bZkp7q19f0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9972ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your video IDs here (or leave blank to input manually)\n",
    "VIDEO_IDS = [\n",
    "    # Add video IDs here, for example:\n",
    "    # \"dQw4w9WgXcQ\",\n",
    "    # \"jNQXAC9IVRw\",\n",
    "]\n",
    "\n",
    "# Manual input if list is empty\n",
    "if not VIDEO_IDS:\n",
    "    manual_input = input(\"Enter YouTube video IDs (comma-separated): \").strip()\n",
    "    if manual_input:\n",
    "        VIDEO_IDS = [v.strip() for v in manual_input.split(',')]\n",
    "\n",
    "if not VIDEO_IDS:\n",
    "    print(\"‚ùå No video IDs provided. Please add videos in the cell above.\")\n",
    "else:\n",
    "    # Fetch transcripts\n",
    "    fetcher = YouTubeTranscriptFetcher()\n",
    "    transcripts = fetcher.fetch_multiple(VIDEO_IDS)\n",
    "    \n",
    "    if transcripts:\n",
    "        total_chars = sum(t['length'] for t in transcripts)\n",
    "        print(f\"\\n‚úÖ Successfully fetched {len(transcripts)} transcript(s)!\")\n",
    "        print(f\"üìä Total: {total_chars:,} characters\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå No transcripts were fetched successfully.\")\n",
    "        print(\"üí° Tip: Make sure videos have captions enabled!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe4750c",
   "metadata": {},
   "source": [
    "## ‚úÇÔ∏è Step 6: Create Text Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f624e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not transcripts:\n",
    "    print(\"‚ùå No transcripts available. Please run Step 5 again.\")\n",
    "else:\n",
    "    # Create LangChain documents\n",
    "    documents = []\n",
    "    for transcript in transcripts:\n",
    "        doc = Document(\n",
    "            page_content=transcript['transcript'],\n",
    "            metadata={\n",
    "                'video_id': transcript['video_id'],\n",
    "                'url': f\"https://www.youtube.com/watch?v={transcript['video_id']}\"\n",
    "            }\n",
    "        )\n",
    "        documents.append(doc)\n",
    "    \n",
    "    # Split into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len\n",
    "    )\n",
    "    \n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    \n",
    "    print(f\"‚úÖ Created {len(chunks)} text chunks\")\n",
    "    print(f\"üìä Average chunk size: {sum(len(c.page_content) for c in chunks) // len(chunks)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3308c6c",
   "metadata": {},
   "source": [
    "## üóÑÔ∏è Step 7: Create Vector Database with Embeddings\n",
    "\n",
    "This creates embeddings for semantic search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062af0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not chunks:\n",
    "    print(\"‚ùå No chunks available. Please run Step 6 again.\")\n",
    "else:\n",
    "    print(f\"üîÑ Creating embeddings using {AI_PROVIDER}...\")\n",
    "    print(\"‚è≥ This may take 1-3 minutes...\\n\")\n",
    "    \n",
    "    # Create embeddings based on provider\n",
    "    if AI_PROVIDER == \"OpenAI\":\n",
    "        embeddings = OpenAIEmbeddings(\n",
    "            model=\"text-embedding-ada-002\"\n",
    "        )\n",
    "        print(\"Using OpenAI text-embedding-ada-002\")\n",
    "        \n",
    "    elif AI_PROVIDER == \"HuggingFace\":\n",
    "        embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "        )\n",
    "        print(\"Using HuggingFace all-MiniLM-L6-v2 (free!)\")\n",
    "    \n",
    "    # Create vector store\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=chunks,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=\"./chroma_db\"\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n‚úÖ Vector database created!\")\n",
    "    print(f\"üìä {len(chunks)} chunks embedded and indexed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e61b2b",
   "metadata": {},
   "source": [
    "## ü§ñ Step 8: Create RAG Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb305d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not vectorstore:\n",
    "    print(\"‚ùå Vector database not created. Please run Step 7 again.\")\n",
    "else:\n",
    "    print(f\"üîÑ Setting up {AI_PROVIDER} chat model...\\n\")\n",
    "    \n",
    "    # Create LLM based on provider\n",
    "    if AI_PROVIDER == \"OpenAI\":\n",
    "        llm = ChatOpenAI(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            temperature=0.7\n",
    "        )\n",
    "        print(\"Using GPT-3.5-turbo\")\n",
    "        \n",
    "    elif AI_PROVIDER == \"HuggingFace\":\n",
    "        llm = HuggingFaceEndpoint(\n",
    "            repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "            temperature=0.7,\n",
    "            max_new_tokens=512,\n",
    "            huggingfacehub_api_token=os.environ.get('HUGGINGFACEHUB_API_TOKEN')\n",
    "        )\n",
    "        print(\"Using Mistral-7B-Instruct-v0.2 (free!)\")\n",
    "    \n",
    "    # Create retrieval QA chain\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=vectorstore.as_retriever(\n",
    "            search_kwargs={\"k\": 4}\n",
    "        ),\n",
    "        return_source_documents=True\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n‚úÖ RAG Chatbot ready!\")\n",
    "    print(f\"üí¨ You can now ask questions about your {len(transcripts)} video(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd97119",
   "metadata": {},
   "source": [
    "## üí¨ Step 9: Chat Function\n",
    "\n",
    "Use `chat(\"your question\")` to ask questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3f3226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(question: str):\n",
    "    \"\"\"Ask a question about your videos\"\"\"\n",
    "    if not qa_chain:\n",
    "        print(\"‚ùå Chatbot not initialized. Please run Step 8.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n‚ùì Question: {question}\\n\")\n",
    "    print(\"ü§î Thinking...\\n\")\n",
    "    \n",
    "    try:\n",
    "        result = qa_chain({\"query\": question})\n",
    "        \n",
    "        print(f\"üí¨ Answer:\\n{result['result']}\\n\")\n",
    "        \n",
    "        # Show sources\n",
    "        if result.get('source_documents'):\n",
    "            print(\"\\nüìö Sources:\")\n",
    "            seen_videos = set()\n",
    "            for i, doc in enumerate(result['source_documents'], 1):\n",
    "                video_id = doc.metadata.get('video_id', 'Unknown')\n",
    "                if video_id not in seen_videos:\n",
    "                    seen_videos.add(video_id)\n",
    "                    print(f\"  ‚Ä¢ Video: {video_id}\")\n",
    "                    print(f\"    URL: https://www.youtube.com/watch?v={video_id}\")\n",
    "        \n",
    "        return result['result']\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "print(\"‚úÖ Chat function ready!\")\n",
    "print(\"\\nüí° Usage: chat('What is this video about?')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679cc6f8",
   "metadata": {},
   "source": [
    "## üéØ Step 10: Test Chat (Examples)\n",
    "\n",
    "Try asking questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fa0809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: General question\n",
    "chat(\"What is this video about?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a287abe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Summarization\n",
    "chat(\"Summarize the main points in 3 bullet points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1682f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask your own question\n",
    "question = input(\"Your question: \")\n",
    "if question:\n",
    "    chat(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4b4839",
   "metadata": {},
   "source": [
    "## üé® Step 11: Interactive UI with Gradio (Optional)\n",
    "\n",
    "Launch a beautiful chat interface!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346ae2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def gradio_chat(message, history):\n",
    "    \"\"\"Gradio chat interface\"\"\"\n",
    "    if not qa_chain:\n",
    "        return \"‚ùå Chatbot not initialized. Please run all previous steps.\"\n",
    "    \n",
    "    try:\n",
    "        result = qa_chain({\"query\": message})\n",
    "        \n",
    "        # Build response with sources\n",
    "        response = result['result']\n",
    "        \n",
    "        if result.get('source_documents'):\n",
    "            response += \"\\n\\n---\\n**üìö Sources:**\\n\"\n",
    "            seen_videos = set()\n",
    "            for doc in result['source_documents'][:3]:\n",
    "                video_id = doc.metadata.get('video_id', 'Unknown')\n",
    "                if video_id not in seen_videos:\n",
    "                    seen_videos.add(video_id)\n",
    "                    response += f\"- [‚ñ∂Ô∏è {video_id}](https://www.youtube.com/watch?v={video_id})\\n\"\n",
    "        \n",
    "        return response\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Error: {str(e)}\"\n",
    "\n",
    "# Create Gradio interface\n",
    "demo = gr.ChatInterface(\n",
    "    fn=gradio_chat,\n",
    "    title=f\"üé• YouTube RAG Chatbot ({AI_PROVIDER})\",\n",
    "    description=f\"Ask questions about {len(transcripts)} YouTube video(s) ‚Ä¢ Powered by {AI_PROVIDER}\",\n",
    "    examples=[\n",
    "        \"What is the main topic of the video?\",\n",
    "        \"Summarize the key points\",\n",
    "        \"What are the most important details?\",\n",
    "        \"Explain this in simple terms\"\n",
    "    ],\n",
    "    theme=gr.themes.Soft()\n",
    ")\n",
    "\n",
    "# Launch with public link\n",
    "print(\"üöÄ Launching Gradio interface...\\n\")\n",
    "demo.launch(share=True, debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193dfc57",
   "metadata": {},
   "source": [
    "## üéâ Congratulations!\n",
    "\n",
    "Your YouTube RAG Chatbot is now running!\n",
    "\n",
    "### ‚úÖ What You Can Do:\n",
    "- **Chat in cells:** Use `chat(\"your question\")` in any code cell\n",
    "- **Use Gradio UI:** Click the public link above for a web interface\n",
    "- **Add more videos:** Go back to Step 5 and add new video IDs\n",
    "- **Switch providers:** Change `AI_PROVIDER` in Step 2 and re-run\n",
    "\n",
    "### üí° Tips:\n",
    "- Videos must have captions/transcripts enabled\n",
    "- HuggingFace is free but slower than OpenAI\n",
    "- The more videos you add, the more knowledge the bot has\n",
    "- Try educational content, tutorials, or lectures for best results\n",
    "\n",
    "### üîÑ To Add More Videos:\n",
    "1. Go to **Step 5**\n",
    "2. Add new video IDs\n",
    "3. Re-run Steps 5-11\n",
    "\n",
    "### üìä Performance:\n",
    "- **OpenAI:** Fast responses (~2-5 seconds), costs ~$0.02 per video\n",
    "- **HuggingFace:** Free, slower responses (~10-30 seconds)\n",
    "\n",
    "---\n",
    "\n",
    "**Enjoy chatting with your YouTube videos! üé¨üí¨**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
